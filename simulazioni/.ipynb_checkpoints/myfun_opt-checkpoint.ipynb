{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f63996",
   "metadata": {},
   "outputs": [],
   "source": [
    "## libraries for NN driven model\n",
    "# Tensorflow / Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras # for building Neural Networks\n",
    "print('Tensorflow/Keras: %s' % keras.__version__) # print version\n",
    "from keras.models import Sequential # for creating a linear stack of layers for our Neural Network\n",
    "from keras import Input # for instantiating a keras tensor\n",
    "from keras.layers import Dense # for creating regular densely-connected NN layers.\n",
    "import keras.metrics as metrics\n",
    "\n",
    "# Sklearn\n",
    "import sklearn # for model evaluation\n",
    "print('sklearn: %s' % sklearn.__version__) # print version\n",
    "# from sklearn.model_selection import train_test_split # for splitting data into train and test samples\n",
    "# from sklearn.metrics import classification_report # for model evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55340730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.myfun_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62038d3b",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3d33ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "global loss_object\n",
    "\n",
    "loss_object = keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e227b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x, y):\n",
    "    \n",
    "    y_ = model(x)\n",
    "    \n",
    "    return loss_object(y_true=y, y_pred=y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c258c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    \n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda8cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_nn(model, scn, epochs, batch_size, v0):\n",
    "    \n",
    "    \"Loss function for the nn-driven model\"\n",
    "\n",
    "    # get the true trajs\n",
    "    tstamps = scn['Tarr']\n",
    "    trajs_true = scn['Xarr']\n",
    "    \n",
    "    # compute the predicted trajs\n",
    "    t_pred, trajs_pred, _ = odesolver_ann_scene(model, scn, epochs, batch_size, v0, verbose=0)\n",
    "    \n",
    "    t_pred_matched, trajs_pred_matched = match_timestamps_scene(t_pred, trajs_pred)\n",
    "\n",
    "    #mse = mean_squared_error(Xhat, Xupd)\n",
    "\n",
    "#     res = 0\n",
    "#     for i in range(0,N):\n",
    "#         for j in range(0,M):\n",
    "#             tmp = Xupd[i][j] - Xhat[i][j]\n",
    "#             res += (tmp**2)/M\n",
    "            \n",
    "#     res = res/N\n",
    "\n",
    "#     if len(set(tstamps - t_pred_matched)) == 1:\n",
    "#         print(f\"timestamps coincide!\\n\\\n",
    "# \\t* tstamps: \\t\\t\\t{tstamps}\\n\\\n",
    "# \\t* np.array(t_ann_list): \\t{t_pred_matched}\")\n",
    "#     else:\n",
    "#         print(f\"There is a mismatch in the timestamps: tstamps != t_pred_matched\")\n",
    "    \n",
    "    return loss_object(y_true=trajs_true, y_pred=trajs_pred_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afff9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_nn(model, scn, epochs, batch_size, v0):\n",
    "    \n",
    "    \"\"\"\n",
    "    tape.gradient(loss_value, model.trainable_variables) is the gradient of loss_value wrt model.trainable_variables\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_nn(model, scn, epochs, batch_size, v0)\n",
    "    \n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
