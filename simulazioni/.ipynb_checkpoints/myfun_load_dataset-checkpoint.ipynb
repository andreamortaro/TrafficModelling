{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe1d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python libraries\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962ee915",
   "metadata": {},
   "source": [
    "# Load Matlab .mat files in Python\n",
    "[source](https://towardsdatascience.com/how-to-load-matlab-mat-files-in-python-1f200e1287b5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c65ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_mat(dirname, flag):\n",
    "    \n",
    "    \"\"\"\n",
    "    Store in a list some info about .mat files, as:\n",
    "    camera, day and sequence of the sample and the pathfile\n",
    "    \"\"\"\n",
    "    \n",
    "    # in order to construct the pathname\n",
    "    prefix, suffix = \"sequence_data\", \".mat\"\n",
    "    match flag:\n",
    "        case \"pre\":\n",
    "            cameras = [\"_1\",\"_2\",\"_3\",\"_4\",\"_5\"]\n",
    "        case \"post\":\n",
    "            cameras = [\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "        case _:\n",
    "            return f\"No match for {flag}, you can only choose between \\\"pre\\\" and \\\"post\\\"\"\n",
    "    days = [\"-1_\"]\n",
    "    sequences = [\"1\",\"2\"]    \n",
    "    \n",
    "    # store the info in a list\n",
    "    info_mat = []\n",
    "    for cam,day,seq in itertools.product(cameras,days,sequences):\n",
    "        filename = prefix+cam+day+seq+suffix\n",
    "        pathfile = os.path.join(dirname, filename)\n",
    "                \n",
    "        info_mat.append([pathfile,cam[-1],day[1],seq])\n",
    "\n",
    "        \n",
    "    return info_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb970506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mat(info):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given an entry of info_mat, I load the .mat file and returns a python dictionary (as data struct).\n",
    "    \"\"\"\n",
    "    pathfile = info[0]      # get the path of the .mat file\n",
    "    mat = loadmat(pathfile) # it returns a python dictionary (as data struct).\n",
    "    \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27eb1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_correct_scn(trajs):\n",
    "    \n",
    "    \"\"\"\n",
    "    Check if a scene is admissible/correct or not. \"Correct\" means if all the trajs are increasing,\n",
    "    so there are not vehicles which are going in the oppoiste way in the motorway.\n",
    "    \"\"\"\n",
    "    \n",
    "    flag = True\n",
    "    wrong_path = [None]\n",
    "    for traj in trajs:\n",
    "        flag = all(earlier <= later for earlier, later in zip(traj, traj[1:]))\n",
    "        if flag == False:\n",
    "            wrong_path = traj\n",
    "            break\n",
    "    return flag, wrong_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfd9400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat2pd(mat,info):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a mat (python dict), this fun converts mat into a pd dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the sequences stored in mat\n",
    "    seqs = mat['sequences']\n",
    "    nscene = seqs.shape[0] # list containing all the number of scenes in each sequences\n",
    "    #print(f\"This sequence has shape: {seqs.shape}, so it has {nscene} scenes\")\n",
    "    \n",
    "    # initialize the list to store info\n",
    "    Xarr, Tarr, Nveh, cons_dis = [],[], [], []\n",
    "    ic_list, wp_list = [], []\n",
    "    \n",
    "    for scn in range(0,nscene): # run over scenes\n",
    "                \n",
    "        tmp = seqs[scn][0][0][0] # (xpos,t) for a scene\n",
    "        x_scn, t_scn = tmp[0], tmp[1][0]     # x position and correspondin timestamps for a fixed scene\n",
    "        flag, wrong_path = is_correct_scn(x_scn)\n",
    "    \n",
    "        Xarr.append(x_scn)\n",
    "        Tarr.append(t_scn)\n",
    "        Nveh.append(len(x_scn))\n",
    "        cons_dis.append(np.diff(x_scn,axis=0))      # consecutive distances of vehicles in this scene\n",
    "        ic_list.append(flag)\n",
    "        wp_list.append(wrong_path)\n",
    "\n",
    "    df = pd.DataFrame({'Tarr': Tarr,\\\n",
    "                       'Xarr': Xarr,\\\n",
    "                       'cons_dis': cons_dis,\\\n",
    "                       'N. vehicles': Nveh,\\\n",
    "                       'cam': info[1],\\\n",
    "                       'day': info[2],\\\n",
    "                       'seq': info[3],\\\n",
    "                       'is_correct': ic_list,\\\n",
    "                       'wrong_path': wp_list})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465394bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_purify(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Avoid rows with not admissible trajs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Consider only correct scenes and drop useless columns\n",
    "    cond = (df['is_correct'] == True)\n",
    "    df_purified = df[cond].drop(['is_correct','wrong_path'], axis=1)\n",
    "    \n",
    "    return df_purified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6994e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    df_standardized = standardize_data(df)\n",
    "\n",
    "    Standardize Xarr and cons_dis over a df, by adding columns to df.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Xarr\n",
    "    Xarr = df['Xarr']\n",
    "    # Mean\n",
    "    XarrRowsMean = [row.mean() for row in df['Xarr']]\n",
    "    XarrMean = np.mean(XarrRowsMean)\n",
    "    # STD\n",
    "    XarrRowsStd = [row.std() for row in df['Xarr']] # standard deviation for all the scenes\n",
    "    XarrStd = np.mean(XarrRowsStd) # mean standard deviation in the df\n",
    "    # Xarr standardized\n",
    "    Xarr_standardized = (Xarr - XarrMean)/XarrStd\n",
    "\n",
    "    ## Cons Dis\n",
    "    cons_dis_standardized = [np.diff(row,axis=0) for row in Xarr_standardized]\n",
    "    \n",
    "    \n",
    "    # Create a new df with new columns\n",
    "    df['Xarr_std'] = Xarr_standardized\n",
    "    df['XarrMean'] = XarrMean\n",
    "    df['XarrStd'] = XarrStd\n",
    "    df['cons_dis_std'] = cons_dis_standardized\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c2a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dirname, flag):\n",
    "    \n",
    "    \"Converting mat into a list of pd dataframe\"\n",
    "    \n",
    "    info_mat = get_info_mat(dirname, flag)\n",
    "    counter = 1\n",
    "    dflist = [] # initialize a list to store all the df, one for each .mat file\n",
    "    dflist2 = []\n",
    "\n",
    "    for info in info_mat: # run over all the sequences\n",
    "    \n",
    "        mat = load_mat(info) # load .mat\n",
    "        df = mat2pd(mat,info) # convert mat into a pd dataframe\n",
    "        df['N. file'] = [counter]*len(df)\n",
    "        \n",
    "        # avoid uncorrect paths and take indexes starting from 0\n",
    "        df_purified = df_purify(df).reset_index(drop=True)\n",
    "        \n",
    "        # standardize data\n",
    "        standardize_data(df_purified)\n",
    "        \n",
    "        dflist.append(df_purified)\n",
    "                \n",
    "        counter += 1\n",
    "\n",
    "    merged_df = pd.concat(dflist)\n",
    "    \n",
    "    return merged_df, dflist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea561c46",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60793039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .mat\n",
    "par_dir = os.path.dirname(os.getcwd()) # parent dir\n",
    "dir_name = par_dir + \"/NN-interaction\"\n",
    "\n",
    "merged_df, dflist = load_dataset(dir_name, 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cebe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacbe308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dflist[0]\n",
    "df_standardized = standardize_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1517a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50e408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
