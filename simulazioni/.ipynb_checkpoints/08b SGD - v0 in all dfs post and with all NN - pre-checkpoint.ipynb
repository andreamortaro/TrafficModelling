{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5273615",
   "metadata": {},
   "source": [
    "# Writing a training loop from scratch\n",
    "https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5e4d47",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84869a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \u001b[38;5;66;03m# for data manipulation\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \u001b[38;5;66;03m# for data manipulation\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tesi/lib/python3.10/site-packages/pandas/__init__.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev  \u001b[38;5;66;03m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[0;32m~/anaconda3/envs/tesi/lib/python3.10/site-packages/pandas/compat/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     is_numpy_dev,\n\u001b[1;32m     20\u001b[0m     np_version_under1p21,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     pa_version_under1p01,\n\u001b[1;32m     24\u001b[0m     pa_version_under2p0,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     pa_version_under9p0,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[0;32m~/anaconda3/envs/tesi/lib/python3.10/site-packages/pandas/compat/numpy/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" support numpy compatibility across versions \"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# numpy versioning\u001b[39;00m\n\u001b[1;32m      7\u001b[0m _np_version \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39m__version__\n",
      "File \u001b[0;32m~/anaconda3/envs/tesi/lib/python3.10/site-packages/pandas/util/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pyright: reportUnusedImport = false\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     Appender,\n\u001b[1;32m      4\u001b[0m     Substitution,\n\u001b[1;32m      5\u001b[0m     cache_readonly,\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     hash_array,\n\u001b[1;32m     10\u001b[0m     hash_pandas_object,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tesi/lib/python3.10/site-packages/pandas/core/util/hashing.py:17\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     TYPE_CHECKING,\n\u001b[1;32m      9\u001b[0m     Hashable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     cast,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lib\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hash_object_array\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     ArrayLike,\n\u001b[1;32m     21\u001b[0m     npt,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/tesi/lib/python3.10/site-packages/pandas/_libs/lib.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.lib\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:216\u001b[0m, in \u001b[0;36m_lock_unlock_module\u001b[0;34m(name)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Python libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd # for data manipulation\n",
    "import numpy as np # for data manipulation\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To enable LaTeX and select a font\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": \"Helvetica\",\n",
    "})\n",
    "\n",
    "# Using ipynb import functions defined in other nb\n",
    "sys.path.append(\"myfun/\")\n",
    "from ipynb.fs.defs.myfun_load_dataset import *\n",
    "from ipynb.fs.full.myfun_models import *\n",
    "from ipynb.fs.full.myfun_nn import *\n",
    "from ipynb.fs.defs.myfun_plot import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0e4056",
   "metadata": {},
   "source": [
    "## Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40328b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_flag = 'pre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab8161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "par_dir = os.path.dirname(os.getcwd()) # parent dir\n",
    "dir_name = par_dir + \"/NN-interaction\"\n",
    "merged_df, dflist = load_dataset(dir_name, processed_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707c9870",
   "metadata": {},
   "source": [
    "## Get $v_{0}$ mean over each df looping on dflist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7592f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "v0_guess = 30\n",
    "NUM_ITER = 500\n",
    "LEARNING_RATE_v0 = 0.5\n",
    "flag_save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef6e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model NN\n",
    "DOE =[[1,2,1], [1,4,1], [1,10,1]] #Design of experiment\n",
    "\n",
    "# Create the dataset\n",
    "dataset = dflist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419e758c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "info_alldataset = []\n",
    "\n",
    "start_time1 = time.time()\n",
    "for DOE_struct in DOE:\n",
    "     \n",
    "    print(\"\\n\")\n",
    "    print(\"==\"*30)\n",
    "    \n",
    "    s = '-'.join(str(x) for x in DOE_struct)\n",
    "    print(f\"NN structure: {s}\")\n",
    "\n",
    "    start_time2 = time.time()\n",
    "    \n",
    "    # Create the model\n",
    "    model = create_model(DOE_struct)\n",
    "    \n",
    "    info_dataset = solve_nn_dataset(model, v0_guess, dataset, NUM_ITER, LEARNING_RATE_v0)\n",
    "    \n",
    "    # Store info about the NN structure\n",
    "    nrow = info_dataset.shape[0]\n",
    "    info_dataset['DOE'] = [DOE_struct]*nrow\n",
    "    info_dataset['processed'] = [processed_flag]*nrow\n",
    "\n",
    "    # Append info_dflist\n",
    "    info_alldataset.append(info_dataset)\n",
    "    \n",
    "    time_taken=time.time() - start_time2\n",
    "    print(f\"\\nTime taken using {s} NN structure: {'{0:.02f}'.format(time_taken)}\")\n",
    "    \n",
    "time_taken=time.time() - start_time1\n",
    "print(f\"\\nTime taken for the computation: {'{0:.02f}'.format(time_taken)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1915917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To better handling info_dataset\n",
    "tmp = info_alldataset\n",
    "info_alldataset = pd.concat(tmp, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622003b",
   "metadata": {},
   "source": [
    "## Prepare the out dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory..\n",
    "if flag_save:\n",
    "    \n",
    "    ext = \".svg\"\n",
    "    \n",
    "    df_seen = [df['N. file'][0] for df in dataset]\n",
    "    df_seen_str = '-'.join(str(x) for x in df_seen)\n",
    "    \n",
    "    # Create directory where to save the image\n",
    "    now = datetime.now() \n",
    "    d = now.strftime(f\"%Y-%m-%d_%H-%M-%S_df{df_seen_str}_{NUM_ITER}it-{processed_flag}\")\n",
    "    \n",
    "    path = 'out/' + d\n",
    "    os.mkdir(path)\n",
    "    \n",
    "    # Save the solution in a file\n",
    "    namefile = '/info_alldataset.txt'\n",
    "\n",
    "    with open(path + namefile, 'w') as output:\n",
    "        info_alldataset.to_csv(path + namefile, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a3be78",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8a7aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms2kmh = 3.6\n",
    "\n",
    "for d in DOE:\n",
    "    \n",
    "    # Initialize the figure\n",
    "    width, height = 7, 5\n",
    "    fig, ax = plt.subplots(figsize=(width,height))\n",
    "    \n",
    "    info_dataset = info_alldataset.loc[info_alldataset['DOE'].isin([d])]\n",
    "    \n",
    "    for _, scn in info_dataset.iterrows():\n",
    "\n",
    "        # Convert velocities to km/h\n",
    "        v0_scn_mean_kmh = scn['v0_scn_mean']*ms2kmh\n",
    "\n",
    "        # For each scene, plot v0 mean (averagin over iterations)\n",
    "        ax.scatter(scn['N. file'], v0_scn_mean_kmh, alpha = .2, color = 'darkblue');\n",
    "\n",
    "    # For a dataset, plot v0 mean (averaging v0 mean in all the scenes)\n",
    "    info_grouped = info_dataset.groupby(['N. file']).mean(numeric_only=True)\n",
    "    for nf, p in info_grouped.iterrows():\n",
    "        ax.plot(nf, p['v0_scn_mean']*ms2kmh, color = 'r', marker=\"x\")\n",
    "\n",
    "    # Plot v0 mean over all dfs\n",
    "    alldfs = [a for a, _ in info_grouped.iterrows()]\n",
    "    v0_mean_alldfs = info_grouped['v0_scn_mean'].mean()*ms2kmh\n",
    "    ax.plot(alldfs, [v0_mean_alldfs]*len(alldfs), color = 'r')  \n",
    "\n",
    "    ax.set_xlabel(r\"$data set$\",fontsize=14)\n",
    "    ax.set_ylabel(r\"$v_{0}\\ [km/h]$\",fontsize=14)\n",
    "    ax.set_title(fr\"$Velocities\\ v_{0}\\ of\\ the\\ leading\\ car$\"\n",
    "                   \"\\n\"  # Newline: the backslash is interpreted as usual\n",
    "                 fr\"$with\\ {NUM_ITER}\\ iter\\ and\\ NN\\ structure\\ {str(d)}$\",fontsize=14)\n",
    "\n",
    "    xlim = [0.75,10.25]\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_xticks(range(1,11))\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    ax.grid(color='grey', linestyle='-', linewidth=0.5);\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    # Save figure\n",
    "    if flag_save:\n",
    "\n",
    "        title = f\"/v0_df{df_seen_str}_{NUM_ITER}it_NN-{str(d[1]).zfill(2)}\"     \n",
    "        fig.savefig(path+title+ext, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8257c2e",
   "metadata": {},
   "source": [
    "> **WARNING**: The maximal km speed allowed on the highway is 100 h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfadcf2",
   "metadata": {},
   "source": [
    "### Plot togheter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa01006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define subplot grid\n",
    "width, height = 7, 5\n",
    "nfig = len(DOE)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=nfig, figsize = (width*nfig,height))\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "suptitle = fr\"$Velocities\\ v_{0}\\ of\\ the\\ leading\\ car,\\ using\\ {NUM_ITER}\\ iter$\"\n",
    "fig.suptitle(suptitle, fontsize=30, y=1.075)\n",
    "\n",
    "ms2kmh = 3.6\n",
    "\n",
    "for ax, d in zip(axes.ravel(), DOE):\n",
    "\n",
    "    # get the right df\n",
    "    info_dataset = info_alldataset.loc[info_alldataset['DOE'].isin([d])]\n",
    "    \n",
    "    for _, scn in info_dataset.iterrows():\n",
    "\n",
    "        # Convert velocities to km/h\n",
    "        v0_scn_mean_kmh = scn['v0_scn_mean']*ms2kmh\n",
    "\n",
    "        # For each scene, plot v0 mean (averagin over iterations)\n",
    "        ax.scatter(scn['N. file'], v0_scn_mean_kmh, alpha = .2, color = 'darkblue');\n",
    "\n",
    "    # For a dataset, plot v0 mean (averaging v0 mean in all the scenes)\n",
    "    info_grouped = info_dataset.groupby(['N. file']).mean(numeric_only=True)\n",
    "    for nf, p in info_grouped.iterrows():\n",
    "        ax.plot(nf, p['v0_scn_mean']*ms2kmh, color = 'r', marker=\"x\")\n",
    "\n",
    "    # Plot v0 mean over all dfs\n",
    "    alldfs = [a for a, _ in info_grouped.iterrows()]\n",
    "    v0_mean_alldfs = info_grouped['v0_scn_mean'].mean()*ms2kmh\n",
    "    ax.plot(alldfs, [v0_mean_alldfs]*len(alldfs), color = 'r')\n",
    "        \n",
    "    ax.set_xlabel(r\"$data set$\",fontsize=14)\n",
    "    ax.set_ylabel(r\"$v_{0}\\ [km/h]$\",fontsize=14)\n",
    "    ax.set_title(fr\"$NN\\ structure\\ {d}$\",fontsize=20)\n",
    "\n",
    "    # Limits\n",
    "    xlim = [0.75,10.25]\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_xticks(range(1,11))\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    ax.grid(color='grey', linestyle='-', linewidth=0.5);\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save figure\n",
    "if flag_save:\n",
    "\n",
    "    title = f\"/v0_df{df_seen_str}_{NUM_ITER}it_NN-ALL\"     \n",
    "    fig.savefig(path+title+ext, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee716c26",
   "metadata": {},
   "source": [
    "### Plot comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the figure\n",
    "width, height = 7, 5\n",
    "fig, ax = plt.subplots(figsize=(width,height))\n",
    "\n",
    "ms2kmh = 3.6\n",
    "\n",
    "palette = ['black', 'royalblue', 'coral']\n",
    "\n",
    "for step, d in enumerate(DOE):   \n",
    "        \n",
    "    # get the right df\n",
    "    info_dataset = info_alldataset.loc[info_alldataset['DOE'].isin([d])]\n",
    "    color = palette[step]\n",
    "\n",
    "    # For a dataset, plot v0 mean (averaging v0 mean in all the scenes)\n",
    "    info_grouped = info_dataset.groupby(['N. file']).mean(numeric_only=True)\n",
    "    for nf, p in info_grouped.iterrows():\n",
    "        ax.scatter(nf, p['v0_scn_mean']*ms2kmh, facecolors='none', edgecolors=color)\n",
    "\n",
    "    # Plot v0 mean over all dfs\n",
    "    alldfs = [a for a, _ in info_grouped.iterrows()]\n",
    "    v0_mean_alldfs = info_grouped['v0_scn_mean'].mean()*ms2kmh\n",
    "    ax.plot(alldfs, [v0_mean_alldfs]*len(alldfs), color = color, label=str(d))\n",
    "\n",
    "ax.set_xlabel(r\"$data set$\",fontsize=14)\n",
    "ax.set_ylabel(r\"$v_{0}\\ [km/h]$\",fontsize=14)\n",
    "ax.set_title(fr\"$Velocities\\ v_{0}\\ of\\ the\\ leading\\ car, with\\ {NUM_ITER}\\ iter$\",fontsize=14)\n",
    "\n",
    "xlim = [0.75,10.25]\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_xticks(range(1,11))\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(color='grey', linestyle='-', linewidth=0.5);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d431b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save figure\n",
    "if flag_save:\n",
    "\n",
    "    title = f\"/v0_df{df_seen_str}_{NUM_ITER}iter_NN-ALL-comparing\"\n",
    "    fig.savefig(path+title+ext, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
