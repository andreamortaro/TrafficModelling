{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d554e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 15:32:03.917554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow/Keras: 2.11.0\n",
      "sklearn: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "## ODE\n",
    "from scipy.integrate import odeint, solve_ivp\n",
    "import numpy as np\n",
    "\n",
    "from ipynb.fs.full.myfun_nn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27b63b7",
   "metadata": {},
   "source": [
    "# Define the LWR models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddce756",
   "metadata": {},
   "source": [
    "## Lin and Log models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6718d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Traffic dynamic with LWR-model\n",
    "\n",
    "def TD_LWR_model(t, X, N, v0, L, flag):\n",
    "    \"\"\"\n",
    "    Lighthill-Whitham-Richards (LWR) traffic flow model in 1D\n",
    "    \"\"\"\n",
    "    #N, v0, L, flag = args[0], args[1], args[2], args[3]\n",
    "    \n",
    "    # W function\n",
    "    match flag:\n",
    "        case \"Lin\":\n",
    "            W = lambda z: v0*(1-1/z)\n",
    "        case \"Log\":\n",
    "            W = lambda z: v0*np.log(z)\n",
    "        case _:\n",
    "            return f\"No match for {flag}, you can only choose between \\\"Lin\\\" and \\\"Log\\\"\"\n",
    "\n",
    "    # ode sys\n",
    "    d_x = np.zeros(N)\n",
    "    \n",
    "    for i in range(0,N-1):\n",
    "        tmp = (X[i+1] - X[i])/L\n",
    "        d_x[i] = W(tmp)\n",
    "\n",
    "    d_x[N-1] = v0\n",
    "        \n",
    "    return d_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d6b935",
   "metadata": {},
   "source": [
    "## NN driven model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd98145",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Traffic dynamic with ANN\n",
    "\n",
    "def TD_ANN_model(t, X, vel):\n",
    "    \n",
    "    \"\"\"\n",
    "    Lighthill-Whitham-Richards (LWR) traffic flow model in 1D\n",
    "    Transform a list as vel into a function of t,X.\n",
    "    \"\"\"\n",
    "    \n",
    "    d_x = vel\n",
    "        \n",
    "    return d_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44fc198",
   "metadata": {},
   "source": [
    "### Ode solver for the NN driven model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62becfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_discretization(t0, tend, deltat=0.05):\n",
    "    \n",
    "    Nt = round((tend-t0)/deltat) + 1               # number of discretization points\n",
    "                                                   # cast the value into int, us round to avoid cast problem\n",
    "    tspan = np.linspace(t0, tend, int(Nt))         # timespan\n",
    "    \n",
    "    return tspan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c299620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def odesolver_ann(x0, vel, t0, tend, deltat = 0.05):\n",
    "    \n",
    "    \"\"\"\n",
    "    odesolver_ann solves the TD_ANN_model ode system:\n",
    "    * in [t0, tend] with timestep as deltat,\n",
    "    * starting from x0\n",
    "    * vel is the rhs passed to TD_ANN_model to create the model\n",
    "    \"\"\"\n",
    "    \n",
    "    tspan_ann = time_discretization(t0,tend,deltat)\n",
    "        \n",
    "    sol_ann = odeint(TD_ANN_model, x0, tspan_ann, args=(vel,), tfirst = True).T\n",
    "\n",
    "    return tspan_ann, sol_ann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04749ec5",
   "metadata": {},
   "source": [
    "### Solve the NN-driven model in a scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcde325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_ann_scene(scn):\n",
    "    \n",
    "    \"\"\"\n",
    "    create_data_ann_scene gives the X and y for an entire scene\n",
    "    \n",
    "    X_scn, y_scn = create_data_ann_scene(scn)\n",
    "    \n",
    "    X_scn is a list of consecutive distances btw the vehicles of a scene, at each timestamps\n",
    "    y_scn is a list of approximated velocities, of all the vehicles except the leader one.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Create X\n",
    "    X_scn = scn['Cons Dis']\n",
    "    \n",
    "    ## Create y\n",
    "    dX_scn = np.diff(scn['Xarr'],axis=1)\n",
    "    dT_scn = np.diff(scn['Tarr'])\n",
    "    velocity = dX_scn/dT_scn # velocity at the timestamps\n",
    "\n",
    "    # we choose the first velocity discretized as (x_(i+1)-x_i)/deltaT\n",
    "    y_scn = velocity[:-1] #drop the last vehicle\n",
    "    \n",
    "    return X_scn, y_scn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55333fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def odesolver_ann_scene(nn_model, scn, epochs, batch_size, v0, deltat=0.05, verbose=\"auto\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    t_ann_list, x_ann_list, vel_ann_list = odesolver_ann_scene(nn_model, scn, epochs, batch_size, v0, deltat=0.05, verbose=\"auto\")\n",
    "    \n",
    "    odesolver_ann_scene solve the ode model driven by a nn in a scene.\n",
    "    \"\"\"\n",
    "    \n",
    "    N = scn['N. vehicles']\n",
    "    tstamps = scn['Tarr']\n",
    "    \n",
    "    vel_ann_list = []\n",
    "    t_ann_list = [scn['Tarr'][0]]\n",
    "    x_ann_list = [[i] for i in scn['Xarr'][:,0]]\n",
    "\n",
    "    X_arr, y_arr = create_data_ann_scene(scn)\n",
    "    \n",
    "    formatter = '{0:.02f}'\n",
    "    \n",
    "    print(\"==\"*50)\n",
    "    print(f\"We have {len(tstamps)-1} time intervals inside [{formatter.format(tstamps[0])},{formatter.format(tstamps[-1])}]\\n\")\n",
    "    \n",
    "    for i in range(0,len(tstamps)-1):\n",
    "\n",
    "        print(\"--\"*50)\n",
    "        print(f\"Time interval n.{i}: [{formatter.format(scn['Tarr'][i])}, {formatter.format(scn['Tarr'][i+1])}]\\n\")\n",
    "        \n",
    "        ## STEP 1: Neural Network\n",
    "        # Create the dataset and train the nn model\n",
    "        X, y = X_arr[:,i], y_arr[:,i]\n",
    "        train_nn(nn_model, X, y, epochs, batch_size, verbose)\n",
    "        \n",
    "        # Predict the rhs of the TD_ANN_model\n",
    "        y_pred = nn_model(X).numpy().flatten().tolist()\n",
    "        vel_ann_list.append(np.append(y_pred,v0).tolist())\n",
    "\n",
    "        print(f\"\\\n",
    "        * y_true: {y}\\n\\\n",
    "        * y_pred: {y_pred}\\n\")\n",
    "        \n",
    "        ## STEP 2: Solve the ODE sys in this time interval\n",
    "        x0 = [l[-1] for l in np.vstack(x_ann_list).tolist()]  # last values computed\n",
    "        t0, tend = scn['Tarr'][i], scn['Tarr'][i+1]\n",
    "        vel_ann = vel_ann_list[i]\n",
    "        tspan_ann, sol_ann = odesolver_ann(x0, vel_ann, t0, tend, deltat)\n",
    "\n",
    "        ## STEP 3: Update x_ann_list, t_ann_list\n",
    "        x_ann = sol_ann.tolist()\n",
    "        t_ann = tspan_ann[1:] # avoid the first recording\n",
    "\n",
    "        # add sol to the correct veh\n",
    "        for j in range(0,N):\n",
    "            tmp = x_ann[j][1:] # avoid the first recording\n",
    "            x_ann_list[j] = np.concatenate([x_ann_list[j],tmp])\n",
    "        t_ann_list = np.concatenate([t_ann_list,t_ann]).tolist()\n",
    "\n",
    "        print(\"--\"*50)\n",
    "    \n",
    "    print(\"==\"*50)\n",
    "    \n",
    "    return t_ann_list, x_ann_list, vel_ann_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80cbf531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_timestamps_scene(t, x, deltat = 0.05):\n",
    "    \n",
    "    \"\"\"\n",
    "    Match the computed solution to the same timestamps of the scene\n",
    "    \n",
    "    t_matched, x_matched = match_timestamps_scene(t, x, deltat = 0.05)\n",
    "    \"\"\"\n",
    "    # To recover the same timestep in the data\n",
    "    factor = int(0.2/deltat)\n",
    "    \n",
    "    t_matched = np.array(t)[::factor]\n",
    "    x_matched = np.array([traj[::factor] for traj in x])\n",
    "    \n",
    "    return t_matched, x_matched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095c499d",
   "metadata": {},
   "source": [
    "### Solve the NN-driven model in a sequence (more scenes $\\rightarrow$ one df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e0eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_ann_seq(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    X_seq, y_seq = [],[]\n",
    "    \n",
    "    # extract input and target for each scene\n",
    "    for row in df.iterrows(): #run over rows\n",
    "        scn = row[1]\n",
    "        X_scn, y_scn = create_data_ann_scene(scn)\n",
    "        \n",
    "        # store in a list\n",
    "        X_seq.append(X_scn)\n",
    "        y_seq.append(y_scn)\n",
    "\n",
    "    return X_seq, y_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12150323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2scn(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    seq = []\n",
    "    \n",
    "    # extract input and target for each scene\n",
    "    for row in df.iterrows(): #run over rows\n",
    "        scn = row[1]\n",
    "        seq.append(scn)\n",
    "\n",
    "    return seq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
