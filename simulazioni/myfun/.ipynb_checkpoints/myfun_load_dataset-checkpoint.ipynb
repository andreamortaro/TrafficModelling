{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fe1d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python libraries\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962ee915",
   "metadata": {},
   "source": [
    "# Load Matlab .mat files in Python\n",
    "[source](https://towardsdatascience.com/how-to-load-matlab-mat-files-in-python-1f200e1287b5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c65ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_mat(dirname, flag):\n",
    "    \n",
    "    \"\"\"\n",
    "    Store in a list some info about .mat files, as:\n",
    "    camera, day and sequence of the sample and the pathfile\n",
    "    \"\"\"\n",
    "    \n",
    "    # in order to construct the pathname\n",
    "    prefix, suffix = \"sequence_data\", \".mat\"\n",
    "    match flag:\n",
    "        case \"pre\":\n",
    "            cameras = [\"_1\",\"_2\",\"_3\",\"_4\",\"_5\"]\n",
    "        case \"post\":\n",
    "            cameras = [\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "        case _:\n",
    "            return f\"No match for {flag}, you can only choose between \\\"pre\\\" and \\\"post\\\"\"\n",
    "    days = [\"-1_\"]\n",
    "    sequences = [\"1\",\"2\"]    \n",
    "    \n",
    "    # store the info in a list\n",
    "    info_mat = []\n",
    "    for cam,day,seq in itertools.product(cameras,days,sequences):\n",
    "        filename = prefix+cam+day+seq+suffix\n",
    "        pathfile = os.path.join(dirname, filename)\n",
    "                \n",
    "        info_mat.append([pathfile,cam[-1],day[1],seq])\n",
    "\n",
    "        \n",
    "    return info_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb970506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mat(info):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given an entry of info_mat, I load the .mat file and returns a python dictionary (as data struct).\n",
    "    \"\"\"\n",
    "    pathfile = info[0]      # get the path of the .mat file\n",
    "    mat = loadmat(pathfile) # it returns a python dictionary (as data struct).\n",
    "    \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c27eb1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_correct_scn(trajs):\n",
    "    \n",
    "    \"\"\"\n",
    "    Check if a scene is admissible/correct or not. \"Correct\" means if all the trajs are increasing,\n",
    "    so there are not vehicles which are going in the oppoiste way in the motorway.\n",
    "    \"\"\"\n",
    "    \n",
    "    flag = True\n",
    "    wrong_path = [None]\n",
    "    for traj in trajs:\n",
    "        flag = all(earlier <= later for earlier, later in zip(traj, traj[1:]))\n",
    "        if flag == False:\n",
    "            wrong_path = traj\n",
    "            break\n",
    "    return flag, wrong_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dfd9400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat2pd(mat,info):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a mat (python dict), this fun converts mat into a pd dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the sequences stored in mat\n",
    "    seqs = mat['sequences']\n",
    "    nscene = seqs.shape[0] # list containing all the number of scenes in each sequences\n",
    "    #print(f\"This sequence has shape: {seqs.shape}, so it has {nscene} scenes\")\n",
    "    \n",
    "    # initialize the list to store info\n",
    "    Xarr, Tarr, Nveh, cons_dis = [],[], [], []\n",
    "    ic_list, wp_list = [], []\n",
    "    \n",
    "    for scn in range(0,nscene): # run over scenes\n",
    "                \n",
    "        tmp = seqs[scn][0][0][0] # (xpos,t) for a scene\n",
    "        x_scn, t_scn = tmp[0], tmp[1][0]     # x position and correspondin timestamps for a fixed scene\n",
    "        flag, wrong_path = is_correct_scn(x_scn)\n",
    "    \n",
    "        Xarr.append(x_scn)\n",
    "        Tarr.append(t_scn)\n",
    "        Nveh.append(len(x_scn))\n",
    "        cons_dis.append(np.diff(x_scn,axis=0))      # consecutive distances of vehicles in this scene\n",
    "        ic_list.append(flag)\n",
    "        wp_list.append(wrong_path)\n",
    "\n",
    "    df = pd.DataFrame({'Tarr': Tarr,\\\n",
    "                       'Xarr': Xarr,\\\n",
    "                       'cons_dis': cons_dis,\\\n",
    "                       'N. vehicles': Nveh,\\\n",
    "                       'cam': info[1],\\\n",
    "                       'day': info[2],\\\n",
    "                       'seq': info[3],\\\n",
    "                       'is_correct': ic_list,\\\n",
    "                       'wrong_path': wp_list})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "465394bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_purify(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Avoid rows with not admissible trajs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Consider only correct scenes and drop useless columns\n",
    "    cond = (df['is_correct'] == True)\n",
    "    df_purified = df[cond].drop(['is_correct','wrong_path'], axis=1)\n",
    "    \n",
    "    return df_purified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6994e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    df_standardized = standardize_data(df)\n",
    "\n",
    "    Standardize Xarr and cons_dis over a df, by adding columns to df.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Xarr\n",
    "    Xarr = df['Xarr']\n",
    "    # Mean\n",
    "    XarrRowsMean = [row.mean() for row in df['Xarr']]\n",
    "    XarrMean = np.mean(XarrRowsMean)\n",
    "    # STD\n",
    "    XarrRowsStd = [row.std() for row in df['Xarr']] # standard deviation for all the scenes\n",
    "    XarrStd = np.mean(XarrRowsStd) # mean standard deviation in the df\n",
    "    # Xarr standardized\n",
    "    Xarr_standardized = (Xarr - XarrMean)/XarrStd\n",
    "\n",
    "    ## Cons Dis\n",
    "    cons_dis_standardized = [np.diff(row,axis=0) for row in Xarr_standardized]\n",
    "    \n",
    "    \n",
    "    # Create a new df with new columns\n",
    "    df['Xarr_std'] = Xarr_standardized\n",
    "    df['XarrMean'] = XarrMean\n",
    "    df['XarrStd'] = XarrStd\n",
    "    df['cons_dis_std'] = cons_dis_standardized\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "991c2a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dirname, flag):\n",
    "    \n",
    "    \"Converting mat into a list of pd dataframe\"\n",
    "    \n",
    "    info_mat = get_info_mat(dirname, flag)\n",
    "    counter = 1\n",
    "    dflist = [] # initialize a list to store all the df, one for each .mat file\n",
    "    dflist2 = []\n",
    "\n",
    "    for info in info_mat: # run over all the sequences\n",
    "    \n",
    "        mat = load_mat(info) # load .mat\n",
    "        df = mat2pd(mat,info) # convert mat into a pd dataframe\n",
    "        df['N. file'] = [counter]*len(df)\n",
    "        \n",
    "        # avoid uncorrect paths and take indexes starting from 0\n",
    "        df_purified = df_purify(df).reset_index(drop=True)\n",
    "        \n",
    "        # standardize data\n",
    "        standardize_data(df_purified)\n",
    "        \n",
    "        dflist.append(df_purified)\n",
    "                \n",
    "        counter += 1\n",
    "\n",
    "    merged_df = pd.concat(dflist)\n",
    "    \n",
    "    return merged_df, dflist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea561c46",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60793039",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/andrea/hetzner/Andrea/Università/master-thesis/mycodes/simulazioni/NN-interaction/sequence_data1-1_1.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/tesi/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/andrea/hetzner/Andrea/Università/master-thesis/mycodes/simulazioni/NN-interaction/sequence_data1-1_1.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m par_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mgetcwd()) \u001b[38;5;66;03m# parent dir\u001b[39;00m\n\u001b[1;32m      3\u001b[0m dir_name \u001b[38;5;241m=\u001b[39m par_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/NN-interaction\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m merged_df, dflist \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(dirname, flag)\u001b[0m\n\u001b[1;32m      8\u001b[0m dflist2 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m info_mat: \u001b[38;5;66;03m# run over all the sequences\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     mat \u001b[38;5;241m=\u001b[39m \u001b[43mload_mat\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# load .mat\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     df \u001b[38;5;241m=\u001b[39m mat2pd(mat,info) \u001b[38;5;66;03m# convert mat into a pd dataframe\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN. file\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [counter]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(df)\n",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m, in \u001b[0;36mload_mat\u001b[0;34m(info)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mGiven an entry of info_mat, I load the .mat file and returns a python dictionary (as data struct).\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m pathfile \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;241m0\u001b[39m]      \u001b[38;5;66;03m# get the path of the .mat file\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathfile\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# it returns a python dictionary (as data struct).\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mat\n",
      "File \u001b[0;32m~/anaconda3/envs/tesi/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:225\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mLoad MATLAB file.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m MR\u001b[38;5;241m.\u001b[39mget_variables(variable_names)\n",
      "File \u001b[0;32m~/anaconda3/envs/tesi/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tesi/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     f, opened \u001b[38;5;241m=\u001b[39m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "File \u001b[0;32m~/anaconda3/envs/tesi/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         file_like \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReader needs file name or open file-like object\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     49\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/andrea/hetzner/Andrea/Università/master-thesis/mycodes/simulazioni/NN-interaction/sequence_data1-1_1.mat'"
     ]
    }
   ],
   "source": [
    "# load .mat\n",
    "par_dir = os.path.dirname(os.getcwd()) # parent dir\n",
    "dir_name = os.path.dirname(par_dir) + \"/NN-interaction\"\n",
    "merged_df, dflist = load_dataset(dir_name, 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cebe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacbe308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dflist[0]\n",
    "df_standardized = standardize_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1517a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50e408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
